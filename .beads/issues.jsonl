{"id":"mcp-databricks-server-0fz","title":"Clean up __init__.py exports (remove or complete)","description":"","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-14T17:44:08.349316-05:00","updated_at":"2025-12-14T17:44:08.349316-05:00"}
{"id":"mcp-databricks-server-1go","title":"Fix lineage helpers to use workspace parameter","description":"","status":"in_progress","priority":1,"issue_type":"bug","created_at":"2025-12-14T17:44:08.193598-05:00","updated_at":"2025-12-14T17:52:11.571499-05:00"}
{"id":"mcp-databricks-server-3oj","title":"Add multi-workspace resolution tests","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:44:15.878334-05:00","updated_at":"2025-12-14T17:44:15.878334-05:00"}
{"id":"mcp-databricks-server-41f","title":"Add workspace parameter to all MCP tools","description":"","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-14T17:44:08.271288-05:00","updated_at":"2025-12-14T17:44:08.271288-05:00"}
{"id":"mcp-databricks-server-9cx","title":"Fix workspace name normalization in _resolve_workspace_name","description":"","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T17:43:05.691709-05:00","updated_at":"2025-12-14T17:45:58.597748-05:00","closed_at":"2025-12-14T17:45:58.597748-05:00"}
{"id":"mcp-databricks-server-bk0","title":"Add debug logging when creating WorkspaceClient","description":"Add logger.debug when creating a new WorkspaceClient in get_workspace_client for easier debugging of multi-workspace behavior.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-14T17:43:47.827917-05:00","updated_at":"2025-12-14T17:43:47.827917-05:00"}
{"id":"mcp-databricks-server-bkx","title":"Remove unused _sdk_client global variable","description":"Now that get_sdk_client delegates to get_workspace_client, the _sdk_client global is unused. Remove it and simplify test fixtures.","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-14T17:43:47.746054-05:00","updated_at":"2025-12-14T17:43:47.746054-05:00"}
{"id":"mcp-databricks-server-fa8","title":"Multi-workspace support epic","description":"Add support for multiple Databricks workspaces with per-session active workspace state. See implementation phases below.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-14T17:24:30.427951-05:00","updated_at":"2025-12-14T17:24:30.427951-05:00"}
{"id":"mcp-databricks-server-fa8.1","title":"Phase 1: Add WorkspaceConfig dataclass","description":"Add WorkspaceConfig dataclass to databricks_sdk_utils.py with fields: name, host, token, sql_warehouse_id","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:45.073652-05:00","updated_at":"2025-12-14T17:27:43.335958-05:00","closed_at":"2025-12-14T17:27:43.335958-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.1","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:45.074367-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.10","title":"Phase 3: Add DatabricksSessionContext dataclass","description":"Add DatabricksSessionContext dataclass to main.py with field: active_workspace: str | None = None. This holds per-MCP-session state.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:05.666988-05:00","updated_at":"2025-12-14T18:04:30.223132-05:00","closed_at":"2025-12-14T18:04:30.223132-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.10","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:05.667382-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.11","title":"Phase 3: Add databricks_session_lifespan()","description":"Add async context manager that creates fresh DatabricksSessionContext for each MCP client session. Wire into FastMCP(..., lifespan=databricks_session_lifespan).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:05.748312-05:00","updated_at":"2025-12-14T18:05:09.940995-05:00","closed_at":"2025-12-14T18:05:09.940995-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.11","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:05.748703-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.12","title":"Phase 3: Add _get_session_workspace() helper","description":"Add helper function that resolves workspace from: 1) explicit param, 2) ctx.request_context.lifespan_context.active_workspace, 3) None (let SDK decide).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:05.812572-05:00","updated_at":"2025-12-14T18:05:39.571266-05:00","closed_at":"2025-12-14T18:05:39.571266-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.12","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:05.812957-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.13","title":"Phase 4: Update all MCP tools with workspace + ctx params","description":"Add workspace: str | None = None and ctx: Context[ServerSession, DatabricksSessionContext] | None = None to all Databricks tools: execute_sql_query, describe_uc_table, get_uc_table_history, describe_uc_catalog, describe_uc_schema, list_uc_catalogs, get_databricks_job, list_databricks_jobs, get_databricks_job_run, get_databricks_job_run_output, list_databricks_job_runs, export_databricks_task_run. Use _get_session_workspace() for resolution.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:11.825165-05:00","updated_at":"2025-12-14T18:11:36.366629-05:00","closed_at":"2025-12-14T18:11:36.366629-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.13","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:11.825551-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.14","title":"Phase 5: Add list_databricks_workspaces tool","description":"Add MCP tool that lists all configured workspaces with name, host, and sql_warehouse_id. Mark active workspace for current session. Returns Markdown.","status":"in_progress","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:19.267669-05:00","updated_at":"2025-12-14T18:13:03.730029-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.14","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:19.268053-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.15","title":"Phase 5: Add get_active_databricks_workspace tool","description":"Add MCP tool that shows the active workspace for the current session. Returns name, host, and sql_warehouse_id as Markdown.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:19.330402-05:00","updated_at":"2025-12-14T17:25:19.330402-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.15","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:19.330771-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.16","title":"Phase 5: Add set_active_databricks_workspace tool","description":"Add MCP tool that sets the active workspace for the current session only. Updates ctx.request_context.lifespan_context.active_workspace. Validates workspace exists before setting.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:19.392951-05:00","updated_at":"2025-12-14T17:25:19.392951-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.16","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:19.393321-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.17","title":"Phase 6: Unit tests for multi-workspace config","description":"Add tests for: env var parsing (default + named workspaces), _resolve_workspace_name() priority logic, get_workspace_client() caching, per-workspace cache keys, error cases (missing token, ambiguous workspace).","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:28.177266-05:00","updated_at":"2025-12-14T17:25:28.177266-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.17","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:28.177658-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.18","title":"Phase 6: Unit tests for per-session workspace state","description":"Add tests for: DatabricksSessionContext isolation between sessions, _get_session_workspace() resolution priority, set_active_databricks_workspace only affects calling session.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:28.245391-05:00","updated_at":"2025-12-14T17:25:28.245391-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.18","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:28.245758-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.19","title":"Phase 6: Update README with multi-workspace docs","description":"Document: env var naming convention, per-session vs per-request workspace selection, example usage with list/set/get workspace tools.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:25:28.314566-05:00","updated_at":"2025-12-14T17:25:28.314566-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.19","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:25:28.314917-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.2","title":"Phase 1: Add _load_workspace_configs_from_env()","description":"Parse env vars at import time. Support DATABRICKS_HOST/TOKEN for 'default' workspace and DATABRICKS_\u003cNAME\u003e_HOST/TOKEN for named workspaces. Skip incomplete configs, reserve 'default' name for legacy vars.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:45.143185-05:00","updated_at":"2025-12-14T17:28:15.29849-05:00","closed_at":"2025-12-14T17:28:15.29849-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.2","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:45.143695-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.3","title":"Phase 1: Add _resolve_workspace_name()","description":"Add function to resolve workspace name with priority: explicit param \u003e 'default' \u003e single workspace \u003e error if ambiguous. Raise DatabricksConfigError with available workspaces on failure.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:45.208202-05:00","updated_at":"2025-12-14T17:28:39.664651-05:00","closed_at":"2025-12-14T17:28:39.664651-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.3","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:45.208571-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.4","title":"Phase 1: Add get_workspace_client(workspace)","description":"Add lazy client factory that creates/caches WorkspaceClient per workspace name. Store in _workspace_clients dict keyed by workspace name.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:45.274751-05:00","updated_at":"2025-12-14T17:29:02.588016-05:00","closed_at":"2025-12-14T17:29:02.588016-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.4","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:45.275136-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.5","title":"Phase 1: Add get_sql_warehouse_id(workspace)","description":"Add helper to get SQL warehouse ID for a workspace from WorkspaceConfig.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:45.342186-05:00","updated_at":"2025-12-14T17:29:22.798894-05:00","closed_at":"2025-12-14T17:29:22.798894-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.5","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:45.342604-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.6","title":"Phase 1: Update get_sdk_client() as backward-compat alias","description":"Change get_sdk_client() to delegate to get_workspace_client() for backward compatibility with existing code.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:45.409238-05:00","updated_at":"2025-12-14T17:31:28.46281-05:00","closed_at":"2025-12-14T17:31:28.46281-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.6","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:45.409626-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.7","title":"Phase 2: Add workspace param to all public SDK functions","description":"Add workspace: str | None = None parameter to: execute_databricks_sql, get_uc_table_details, get_uc_schema_details, get_uc_catalog_details, get_uc_all_catalogs_summary, get_table_history, list_jobs, get_job, list_job_runs, get_job_run, get_job_run_output, export_task_run. Use get_workspace_client(workspace) instead of get_sdk_client().","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:56.679193-05:00","updated_at":"2025-12-14T17:38:21.689312-05:00","closed_at":"2025-12-14T17:38:21.689312-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.7","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:56.679523-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.8","title":"Phase 2: Update caches to per-workspace keys","description":"Change _job_cache and _notebook_cache to use (workspace_name, id) tuple keys instead of just id. Update _get_job_info_cached and _get_notebook_id_cached to accept workspace param and use composite keys.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:56.742799-05:00","updated_at":"2025-12-14T17:52:06.402751-05:00","closed_at":"2025-12-14T17:52:06.402751-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.8","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:56.743156-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-fa8.9","title":"Phase 2: Forward workspace through helper chains","description":"Update _resolve_notebook_info_optimized, _process_lineage_results, _get_table_lineage and other internal helpers to accept and forward workspace parameter.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T17:24:56.811136-05:00","updated_at":"2025-12-14T18:04:02.302433-05:00","closed_at":"2025-12-14T18:04:02.302433-05:00","dependencies":[{"issue_id":"mcp-databricks-server-fa8.9","depends_on_id":"mcp-databricks-server-fa8","type":"parent-child","created_at":"2025-12-14T17:24:56.811524-05:00","created_by":"daemon"}]}
{"id":"mcp-databricks-server-ffs","title":"Fix stdout pollution and SQL injection vulnerability","description":"Fixed two critical bugs:\n1. Removed `print()` statements in `databricks_formatter.py` that polluted stdout and broke MCP stdio transport.\n2. Fixed SQL injection vulnerability in `_get_table_lineage` by using parameterized queries.\nAlso fixed environment setup for tests.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-22T14:31:20.969295-05:00","updated_at":"2025-11-22T14:31:27.481793-05:00","closed_at":"2025-11-22T14:31:27.481793-05:00"}
{"id":"mcp-databricks-server-i0w","title":"Remove stale module-level globals (DATABRICKS_HOST, TOKEN, etc)","description":"","status":"open","priority":2,"issue_type":"chore","created_at":"2025-12-14T17:43:05.85522-05:00","updated_at":"2025-12-14T17:43:05.85522-05:00"}
{"id":"mcp-databricks-server-id6","title":"Remove dead legacy API format branch in databricks_formatter.py","description":"","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-14T17:44:08.427233-05:00","updated_at":"2025-12-14T17:44:08.427233-05:00"}
{"id":"mcp-databricks-server-im0","title":"Reject empty string workspace name","description":"In _resolve_workspace_name, treat empty string workspace as invalid input and raise error instead of falling back to default.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T17:43:47.989831-05:00","updated_at":"2025-12-14T17:43:47.989831-05:00"}
{"id":"mcp-databricks-server-ixp","title":"Add fixture for multi-workspace test scenarios","description":"Add pytest fixture setup_two_workspaces that configures both default and dev workspaces for testing multi-workspace behavior.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:43:47.909162-05:00","updated_at":"2025-12-14T17:43:47.909162-05:00"}
{"id":"mcp-databricks-server-kil","title":"Add thread locks to caches (_workspace_clients, _job_cache, _notebook_cache)","description":"","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T17:44:08.11522-05:00","updated_at":"2025-12-14T17:53:38.258952-05:00","closed_at":"2025-12-14T17:53:38.258952-05:00"}
{"id":"mcp-databricks-server-lgu","title":"Remove legacy globals (_sdk_client, DATABRICKS_HOST, etc.)","description":"","status":"open","priority":2,"issue_type":"chore","created_at":"2025-12-14T17:44:08.039124-05:00","updated_at":"2025-12-14T17:44:08.039124-05:00"}
{"id":"mcp-databricks-server-onu","title":"Add multi-workspace unit tests","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:43:05.943992-05:00","updated_at":"2025-12-14T17:43:05.943992-05:00"}
{"id":"mcp-databricks-server-twf","title":"Add tests for SQL timeout/failure states","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:44:15.955286-05:00","updated_at":"2025-12-14T17:44:15.955286-05:00"}
{"id":"mcp-databricks-server-u0h","title":"Add logging for incomplete workspace configs","description":"","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T17:43:05.776475-05:00","updated_at":"2025-12-14T17:43:05.776475-05:00"}
{"id":"mcp-databricks-server-vzm","title":"Update README to document multi-workspace configuration","description":"","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T17:44:16.112291-05:00","updated_at":"2025-12-14T17:44:16.112291-05:00"}
{"id":"mcp-databricks-server-wfg","title":"Split databricks_sdk_utils.py into focused modules","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T17:44:16.033872-05:00","updated_at":"2025-12-14T17:44:16.033872-05:00"}
